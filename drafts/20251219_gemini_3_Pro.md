What do you think about this thing I found?

# Polyhedral Mesa Gaussians: The Implicit Geometry of ReLU Networks

## 1. Introduction

The interpretation of neural network activations remains a subject of debate despite the ubiquity of the architecture. The prevailing intuition treats neurons as **template matchers**: a neuron is thought to "fire" when it detects its preferred stimulus, with the magnitude of activation representing the network's confidence in the feature's presence [Oursland, 2024]. Under this view, the weight vector  acts as a template, and the dot product  measures the similarity between the input and the template. This intuition draws heavily on cosine similarity, implying that large positive values indicate a "perfect match" or high certainty [Oursland, 2025].

However, this "confidence interpretation" faces a fundamental geometric contradiction: standard linear layers compute the unnormalized inner product, not the cosine similarity. Without strict normalization of both weights and inputs—which is not enforced in standard architectures—the magnitude of the output is confounded by the magnitude of the input vector. A vector pointing 45° away from the template can produce a larger activation than a perfectly aligned vector simply by having a larger norm. Consequently, the raw activation magnitude cannot reliably signal confidence in feature presence without additional constraints [Oursland, 2024].

We propose an alternative framework that requires no such normalization: the **Distance Interpretation**. We argue that standard feedforward networks with ReLU activations are better understood not as template matchers, but as estimators of **Polyhedral Mesa Gaussians (PMGs)**.

In this view, we perform an **Interpretive Inversion** [Oursland, 2024]:

1. **Zero activation** does not mean "failure to detect"; it represents the **ideal state** where the input lies within a learned prototype region.
2. **Positive activation** does not mean "confidence"; it represents **deviation** or **constraint violation**—the distance of the input from the surface of the prototype region.
3. **The Prototype** is not a single point (centroid) but a **convex polytope** (mesa) defined by the intersection of hyperplane constraints [Montúfar et al., 2014].

This framework recontextualizes the ReLU operation  as a calculation of the one-sided distance from a boundary, rather than a measure of alignment. Deep networks, then, do not build hierarchies of complex templates; they build **hierarchies of polytopes**, refining the "inside vs. outside" distinction by composing constraints in increasingly abstract distance spaces [Montúfar et al., 2014].

This geometry mirrors the "Mesa" functions originally developed for biomedical signal processing to model flat-topped physiological waveforms [Dubois et al., 2007]. By generalizing these 1D primitives to high-dimensional polyhedral geometry, we show that ReLU networks implicitly estimate a specific class of probability densities—Polyhedral Mesa Gaussians—where the probability mass is concentrated on a flat plateau bounded by soft constraints. This aligns closely with **Energy-Based Models**, where the "ground state" is the region of zero energy (zero activation) [LeCun et al., 2006].

This paper formalizes this geometric interpretation. We derive the Polyhedral Mesa Gaussian from first principles, show its algebraic isomorphism to ReLU networks, and discuss how this "Constraint-Based" view resolves long-standing interpretability puzzles, offering a geometric bridge to cognitive theories of categorization [Rosch, 1975].

## 2. Background: From Signal Processing to High-Dimensional Geometry

To understand the geometric primitives of neural networks, we first look to signal processing, where the need to model "flat-topped" distributions arose decades ago in the analysis of electrocardiograms (ECG).

### The Gaussian Mesa Function (GMF)

In standard Gaussian modeling, the bell curve is defined strictly by its mean and variance. This creates a rigid coupling between the peak's location and its width: a standard Gaussian cannot model a sustained "plateau" of activation without becoming diffusely wide. This limitation proved problematic for modeling physiological signals, specifically the P, Q, R, S, and T waves of the ECG cycle, which often exhibit flat tops or asymmetric rise and fall times.

To address this, Dubois et al. (2007) introduced the **Gaussian Mesa Function (GMF)**. The GMF decouples the "peak location" from the "peak duration," allowing for a parameterizable plateau region where the function value remains constant before decaying.

Formally, the univariate GMF was defined as a piecewise function:

This formulation successfully captures the "mesa" geometry—a flat top with Gaussian tails—allowing for precise segmentation of biological waveforms.

### The High-Dimensional Gap

While the GMF is effective for 1D time-series, its original formulation is ill-suited for the high-dimensional latent spaces of neural networks. The definition relies on explicit `case` statements to handle the plateau boundaries. In high-dimensional vector spaces, boundaries are not simple scalar thresholds but complex hypersurfaces. Generalizing a piecewise scalar function to  using `if-else` logic is mathematically clumsy and computationally inefficient for gradient-based optimization.

To lift the "Mesa" concept into the domain of deep learning, we need a formulation that is algebraic rather than piecewise.

### The Bridge: Mahalanobis Distance and Ridge Functions

The natural language of geometry in high-dimensional statistics is the **Mahalanobis Distance** (). For a vector , the standard Mahalanobis distance normalizes the Euclidean distance by the covariance structure of the data:

In standard multivariate Gaussian models, this distance defines ellipsoidal level sets. To construct a "Multivariate Mesa," we must modify this distance metric to support flat plateaus (hyper-rectangles or polytopes) instead of pure ellipsoids, while retaining the algebraic smoothness required for learning.

In the following sections, we derive a new metric—the **Mesa Mahalanobis Distance**—that achieves this generalization. We show how standard neural network layers act as **Ridge Functions** (projections of the form ) that implicitly compute these rectified distances, effectively implementing the GMF geometry in high-dimensional space.


## 3. Theory Part I: Deriving the Mesa

To implement the "interpretive inversion" mathematically, we must construct a distance metric that supports the "mesa" geometry: a flat plateau of zero distance (the prototype) surrounded by quadratic growth (the penalty). We derive this metric in three stages: first in one dimension, then extending to orthogonal multivariate space, and finally generalizing to arbitrary polyhedral constraints.

### Univariate Construction: The Rectified Distance

The standard one-dimensional Mahalanobis distance is defined as . This metric has a single minimum at . To create a plateau, we need a metric that is zero over an interval.

We begin with the algebraic identity that decomposes the absolute value into two opposing Rectified Linear Units (ReLUs):

This identity partitions the distance into a "right-side" component and a "left-side" component. To create a plateau of width , we shift these components outward by . This yields the **Mesa Mahalanobis Distance** ():

This function creates three distinct regions:

1. **The Plateau** (): Both ReLU terms are zero, yielding .
2. **The Tails** (): The distance increases linearly, equivalent to the standard Mahalanobis distance shifted by the margin .

By exponentiating the squared distance, , we recover the flat-topped Gaussian Mesa Function used in signal processing, but derived now from simple rectified linear operations.

### Multivariate Extension: The Hyper-Rectangle

We extend this to  via Principal Component Analysis (PCA). A standard multivariate Gaussian is defined by the Mahalanobis distance . Using the eigendecomposition , this distances decomposes into the sum of squared distances along  orthogonal principal axes.

We apply the Mesa transformation component-wise to these principal axes. For each axis , we define two opposing constraints:

where  is the projection onto the -th eigenvector.

The total **Multivariate Mesa Distance** is the Euclidean norm of all  constraint violations:

Geometrically, the zero-distance region () is the intersection of these  "slab" constraints. Since the eigenvectors are orthogonal, this intersection forms an oriented **Hyper-Rectangle** (or box) centered at .

### Polyhedral Generalization: The Product of Experts

The restriction to orthogonal axes (hyper-rectangles) is too limiting for general representation learning. Neural networks often learn redundant or non-orthogonal features. To generalize, we relax the requirement for orthogonal eigenvectors  and allow for a set of  arbitrary normal vectors .

This leads to the **Polyhedral Mesa Gaussian (PMG)**. Instead of a mean and covariance, the distribution is defined by a set of  soft half-space constraints. The distance from the -th constraint is:

The total **Polyhedral Mesa Distance** is the L2 aggregation of these individual violations:

The plateau region  is the intersection of  half-spaces, forming a convex polytope.

#### Convexity and Optimization

A critical property of the PMG is that its negative log-likelihood, , is a **convex function** with respect to . This follows because  is convex, its square  is convex, and the sum of convex functions is convex. This ensures that finding the "prototype" (the projection of any point onto the mesa) is a well-posed convex optimization problem, guaranteeing the stability of the representation [Boyd & Vandenberghe, 2004].

This construction effectively treats the distribution as a **Product of Experts** model [Hinton, 2002], where each constraint acts as an independent "expert" carving away low-probability regions of the input space.

## 4. Theory Part II: The Neural Isomorphism

Having derived the Polyhedral Mesa Gaussian (PMG) from first principles, we now turn to the central claim of this paper: that standard feedforward neural networks with ReLU activations are, algebraically and geometrically, estimators of PMGs. This is not merely an analogy; it is an isomorphism.

### The Mapping: ReLU Layers as PMG Log-Likelihoods

Consider a single neuron in a standard ReLU layer. The activation is given by .

In our PMG derivation, the distance from a single constraint  is defined as:

By equating these two expressions, we can map the neural network parameters directly to the geometric parameters of the PMG:

1. **Constraint Normal ():** The weight vector direction  defines the normal vector of the hyperplane constraint.
2. **Constraint Precision ():** The magnitude of the weight vector  corresponds to . A larger weight implies a steeper penalty slope, effectively creating a "harder" constraint (smaller variance ).
3. **Constraint Margin ():** The bias term  defines the location of the constraint boundary relative to the origin. Specifically,  sets the threshold.

Thus, a single hidden layer with  ReLU neurons computes the vector of constraint violations . If the subsequent layer computes a weighted sum of these activations (as in the output layer of a network), it is calculating the squared Polyhedral Mesa Distance  (or an L1 approximation thereof).

The network's output is therefore proportional to the negative log-likelihood of a Polyhedral Mesa Gaussian:

### Hierarchy of Polytopes

Deep networks do not simply learn a single static polytope. Instead, they construct a **Hierarchy of Polytopes**.

In a multi-layer network, the first layer defines a set of hyperplanes in the raw input space . The intersection of these half-spaces forms the initial "Level 1" polytope. The activations  represent the *distance profile* of the input relative to this polytope.

The second layer weights matrix  then acts upon this distance profile. A neuron in the second layer computes . This defines a new hyperplane constraint, but this constraint exists in the *distance space* of the previous layer.

* **Layer 1:** Defines a polytope in Input Space ().
* **Layer 2:** Defines a polytope in "Violation Space" ().
* **Layer 3:** Defines a polytope in "Distance-of-Distance Space" ().

Each layer progressively refines the "inside vs. outside" distinction. A point is "accepted" by Layer 2 only if its profile of violations from Layer 1 satisfies a new set of aggregate constraints. This hierarchical composition allows the network to carve out increasingly complex, non-local regions of the original input space.

### Handling Non-Convexity: The XOR Geometric Proof

A single PMG is provably convex (the intersection of half-spaces). However, real-world categories (e.g., "Red objects") are often non-convex unions of disjoint clusters. How can a convexity-based theory explain this?

The answer lies in the interaction between layers, specifically through **negative weights** or subtractive interference, which allows for the construction of unions.

Consider the classic XOR problem, the simplest non-convex dataset. It consists of two disjoint "true" regions. A single layer cannot solve this. However, a two-layer ReLU network solves it by intersecting constraints to form *two separate* mesas.

* **Neuron 1** creates a constraint .
* **Neuron 2** creates a constraint .
* **Neuron 3** (subtractive) can cancel out the middle region.

Mathematically, the network forms a function like . While each component is convex, the difference or weighted sum allows the network to represent a **Union of Convex Mesas**.

This demonstrates that while the *primitive* unit of the network is a convex polytope, the *expressive capacity* of the deep hierarchy covers complex, non-convex manifolds by stitching these convex primitives together—essentially performing a "Polyhedral Spline" approximation of the data manifold [Balestriero & Baraniuk, 2018].


## 5. Synthesis: Explaining Empirical Phenomena

The value of a theoretical framework lies in its ability to predict or explain observed phenomena. The Polyhedral Mesa Gaussian (PMG) framework makes a strong geometric prediction: if neural networks essentially estimate probability densities defined by intersection of constraints, then the learned representations of concepts should manifest as convex polytopes in the latent space.

Recent empirical studies in mechanistic interpretability and geometric deep learning provide converging evidence for this prediction.

### Prediction 1: Concepts Have Polyhedral Shapes

The most direct validation of the Mesa framework is the finding that learned concepts are not "points" or "clouds" but rigorously defined **polytopes**.

Park et al. (2024) analyzed the geometry of concepts in Large Language Models (LLMs) like LLaMA-3. They found that simple categorical concepts (e.g., "mammal", "bird") are represented as **simplices**—the simplest form of polytope. Furthermore, they showed that complex concepts are constructed as polytopes formed from the direct sums of these simpler simplices, matching the hierarchical composition prediction of our framework.

Similarly, in computer vision, Lee et al. (2024) demonstrated that popular datasets like MNIST and CIFAR-10 can be efficiently encapsulated by "Polytope-Basis Covers," where each class is bounded by as few as two polytopes. Fan et al. (2023) further corroborated this by showing that despite the theoretical capacity of deep ReLU networks to create fractally complex regions, trained networks consistently converge to "surprisingly simple" polytopes.

This confirms the core tenet of the PMG: the fundamental unit of neural representation is the convex polytope.

### Prediction 2: Sparse Coding and Antipodal Structures

The "Symmetric" form of our theory (the Multivariate Mesa Gaussian) predicts that to bound a feature on both sides (e.g., "not too hot, not too cold"), the network must learn **antipodal pairs** of constraints—normals pointing in opposite directions.

Evidence for this "Antipodal Feature Storage" appears in both classical and modern literature.

* **Sparse Coding:** The seminal work of Olshausen & Field (1996) showed that maximizing sparsity leads to Gabor filters that tile space. Mathematically, the L1-norm sparsity constraint creates a **Cross-Polytope** (the geometric dual of the hypercube), which is defined by strictly antipodal constraints.
* **Toy Models:** Recent investigations into "Toy Models of Superposition" have explicitly observed that when features are anti-correlated, networks store them antipodally to maximize geometric efficiency. "Benign collisions" also occur where opposite-signed weights coexist on neurons without interference, effectively implementing the  logic.

**The Simplex vs. Box Nuance:**
While the *ideal* symmetric mesa is a Hyper-Rectangle (requiring antipodal pairs), empirical results often favor **Simplices** (triangles/tetrahedrons). A simplex is the most efficient way to bound a region, requiring only  constraints to bound  dimensions, whereas a box requires .
The PMG framework accommodates both: a Hyper-Rectangle is a PMG with symmetric constraints, while a Simplex is a PMG with minimal constraints. The prevalence of simplices suggests networks trade symmetry for parameter efficiency (sparsity), learning the minimal set of hyperplanes needed to define a "good enough" mesa.

### Prediction 3: Adversarial Vulnerability as Boundary Crossing

The "Confidence" interpretation struggles to explain adversarial examples: why does an imperceptible noise pattern make the network "confident" it is seeing a gibbon?

Under the Mesa framework, this vulnerability is geometric. If a class is defined by a polytope, an "adversarial attack" is simply a trajectory that pushes a point across the nearest constraint boundary.

* **DeepFool:** The DeepFool algorithm [Moosavi-Dezfooli et al., 2016] explicitly assumes that the decision boundary is a polytope and computes the shortest path to a facet. The success of DeepFool confirms that the decision boundaries are indeed locally polyhedral (flat facets), not curved manifolds.
* **The "Thin Shell" Problem:** Because the "Mesa" is defined by the intersection of many half-spaces, high-dimensional polytopes often have "pointy" corners or thin regions. An input might be inside the prototype region (zero activation) but very close to a constraint surface. A small perturbation pushes it out (activation ), causing the "Distance" to spike, which the Softmax layer misinterprets as a high-confidence detection of a competing class.

---

### References

## 6. Discussion: Cognitive Implications

The mathematical isomorphism between ReLU networks and Polyhedral Mesa Gaussians offers more than just a geometric understanding of deep learning; it suggests a fundamental shift in how we model categorization and recognition in intelligent systems. This shift parallels long-standing debates in cognitive science regarding the nature of concepts.

### Prototype Theory: Centroids vs. Boundaries

In cognitive psychology, Prototype Theory posits that categories are organized around a central, ideal exemplar [Rosch, 1975]. The standard "Confidence Interpretation" of neural networks aligns with a **Centroid-based** view of prototypes: a neuron represents a "perfect dog," and recognition is a measure of similarity to this average template.

The Mesa framework enforces a **Boundary-based** (or Region-based) view. Here, the prototype is not a single point but a volume—the "Mesa plateau".

* **Centroid View:** A Chihuahua is a "bad dog" because it is far from the average "Golden Retriever-like" center.
* **Mesa View:** A Chihuahua is a "perfect dog" (zero distance) because it resides fully within the boundaries of the dog polytope.

This distinction is crucial. In high-dimensional spaces, the "average" of a class often lies in a region of low probability (the "soap bubble" effect of high-dimensional Gaussians). The Mesa interpretation avoids this pathology. It suggests that neural networks do not learn what a dog *is* (the template); they learn what a dog *is not* (the constraints). Recognition becomes a process of exclusion: a concept is defined by the set of all inputs that fail to violate its specific constraints.

### Solving the Open World Problem

One of the most persistent failures of deep learning is the "Open World" problem: standard Softmax classifiers are famously overconfident, assigning high probability to noise or out-of-distribution inputs because they force every input into one of  classes (Closed World assumption).

The Mesa framework provides a natural, geometric solution to this.
Because the output of the network is fundamentally a **distance** (), it has an interpretable magnitude that correlates with "anomaly" or "novelty".

* If an input falls inside a prototype mesa (), it is a known class.
* If an input falls outside *all* learned mesas (), it is explicitly "Unknown."

This aligns with heuristic approaches like OpenMax [Bendale & Boult, 2016], which replace Softmax with distance-based rejection. Our theory suggests that OpenMax wasn't just a heuristic fix; it was restoring the "native" distance metric that the network was computing all along, which the final Softmax layer had obscured.

### The Role of Negative Weights: Sculpting the Manifold

While positive weights implement the **Intersection** of constraints (building a convex mesa), negative weights have often been difficult to interpret geometrically. In the Mesa framework, negative weights act as **sculpting tools** that implement **Union** or **Exclusion** operations.

If positive weights define the "block of marble" (the convex hull), negative weights carve out holes or concave regions. This allows the network to approximate complex, non-convex manifolds (like the "Donut" or "Crescent" shapes of real data distributions) by subtracting one convex mesa from another.

* **Excitatory Connections (Positive):** "To be a Mug, you must be cylinder-like AND have a handle." (Intersection).
* **Inhibitory Connections (Negative):** "BUT you must NOT be a Bucket." (Exclusion).

This view reframes inhibition not merely as "suppression" but as a precise geometric operation—**Difference of Convex (DC) Decomposition**—essential for modeling the nuanced boundaries of real-world categories.

---

### References


## 7. Conclusion

The success of deep learning has often been framed as an empirical triumph awaiting a theoretical explanation. This paper argues that the explanation has been hiding in plain sight, obscured only by a persistent intuition that neurons behave like biological template matchers. By performing an **Interpretive Inversion**—viewing activation as **distance** rather than **confidence**—we reveal that the standard ReLU network is not a "black box" but a rigorous estimator of a specific geometric and probabilistic object: the **Polyhedral Mesa Gaussian (PMG)**.

We demonstrated that the "Mesa" geometry, originally derived for biological signal processing to model flat-topped distributions, emerges naturally from the algebra of rectified linear units. By mapping weights to constraint normals and biases to margins, we showed that feedforward networks build a **hierarchy of polytopes**, refining the "inside vs. outside" distinction through layers of increasing abstraction.

This framework resolves critical interpretability puzzles. It explains why "confidence" (activation magnitude) is unreliable without normalization, whereas "distance" remains geometrically robust. It provides a principled reason for the adversarial vulnerability of deep networks—not as a failure of template matching, but as the geometric inevitability of crossing thin constraint boundaries in high dimensions. Furthermore, it connects the mechanics of deep learning to the cognitive science of categorization, validating a **Boundary-based** view of concepts where meaning is defined by exclusion rather than averaging.

Ultimately, we do not need to invent new mathematics to explain why deep learning works. We simply need to invert our interpretation of the mathematics we already have. When we view the neuron not as a light bulb that signals presence, but as a guard rail that signals deviation, the deep network reveals itself as a sophisticated hierarchy of constraint-satisfaction mechanisms, constructing convex islands of meaning in a high-dimensional sea of noise.

## Bibliography

* **Balestriero, R., & Baraniuk, R. G.** (2018). "Mad Max: Affine Spline Construction of Deep Neural Networks." *International Conference on Machine Learning (ICML)*.
* **Bendale, A., & Boult, T. E.** (2016). "Towards Open Set Deep Networks." *CVPR*.
* **Boyd, S., & Vandenberghe, L.** (2004). *Convex Optimization*. Cambridge University Press.
* **Dubois, R., Maison-Blanche, P., Quenet, B., & Dreyfus, G.** (2007). "Automatic ECG wave extraction in long-term recordings using Gaussian mesa function models and nonlinear probability estimators." *Computer Methods and Programs in Biomedicine*, 88(3), 217-233.
* **Fan, F., et al.** (2023). "Deep ReLU Networks Have Surprisingly Simple Polytopes." *arXiv preprint arXiv:2305.09145*.
* **Hinton, G. E.** (2002). "Training products of experts by minimizing contrastive divergence." *Neural Computation*, 14(8), 1771-1800.
* **LeCun, Y., Chopra, S., Hadsell, R., Ranzato, M., & Huang, F.J.** (2006). "A tutorial on energy-based learning." *Predicting Structured Data*, MIT Press.
* **Lee, H., Mammadov, R., & Ye, J.** (2024). "Defining Neural Network Architecture through Polytope Structures of Datasets." *ICML*.
* **Mahalanobis, P. C.** (1936). "On the generalised distance in statistics." *Proceedings of the National Institute of Sciences of India*.
* **Montúfar, G., Pascanu, R., Cho, K., & Bengio, Y.** (2014). "On the number of linear regions of deep neural networks." *Proceedings of NIPS*.
* **Moosavi-Dezfooli, S. M., et al.** (2016). "DeepFool: a simple and accurate method to fool deep neural networks." *CVPR*.
* **Olshausen, B. A., & Field, D. J.** (1996). "Emergence of simple-cell receptive field properties by learning a sparse code for natural images." *Nature*, 381(6583), 607-609.
* **Oursland, A.** (2024a). "Interpreting Neural Networks through Mahalanobis Distance." *arXiv preprint arXiv:2410.19352*. 
* **Oursland, A.** (2024b). "Neural Networks Use Distance Metrics." *arXiv preprint arXiv:2411.17932v1*. 
* **Oursland, A.** (2025). "Neural Networks Learn Distance Metrics." *arXiv preprint arXiv:2502.02103*.
* **Park, K., et al.** (2024). "The Geometry of Categorical and Hierarchical Concepts in Large Language Models." *arXiv preprint arXiv:2406.01506*.
* **Rosch, E.** (1975). "Cognitive representations of semantic categories." *Journal of Experimental Psychology: General*, 104(3), 192.

---

### **Visual Strategy (Crucial for Theory Papers)**

Since you have no experimental plots, your **diagrams** must be high-quality. I recommend:

1. **The "Inversion" Diagram:**
* Left: Standard "Cone of Confidence" (Vectors pointing out).
* Right: PMG "Crystal of Constraints" (Facets bounding a region).


2. **The "Construction" Diagram:**
* Show step-by-step: ReLU    Tub  Gaussian Mesa.


3. **The "Hierarchy" Diagram:**
* Show how 2D hyperplanes (Layer 1) intersect to form a 2D Polygon (Layer 2).



